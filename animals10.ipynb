{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eedbf5d3",
   "metadata": {},
   "source": [
    "## TODO\n",
    "rename file folders -- done \n",
    "check if differenet image count per class is problem -- \n",
    "load the dataset probably -- \n",
    "resize images via PIL Image load > convert to torch tensor or directly loading it via torchvision read image --\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169cf9ee",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e90c09e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#to load the dataset and to split the dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "#for resizing of images\n",
    "from torchvision import transforms\n",
    "#to read images from path\n",
    "from torchvision.io import read_image\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6107da65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory:  c:\\Users\\adamg\\Desktop\\Ulohy\\3 vyska\\ZNEUS\\cvika\\zadania\\zadanie 2\\archive/raw-img\n"
     ]
    }
   ],
   "source": [
    "#simply getting working directory and appending the archive directories to it\n",
    "base_dir = os.getcwd()\n",
    "dataset_dir = os.path.join(base_dir, \"archive/raw-img\")\n",
    "print(\"Dataset directory: \", dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3ab94f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment, by which i determined that the average size of the images is 250x320 (width x height)so i will would resize it to that size but working with width=height is easier so the size would be 250x250, but from presentation of CNN we learned that resizing them to 224x224 could be better\n",
    "# average_height = 0\n",
    "# average_width = 0\n",
    "# images_count = 0\n",
    "# for file_name in os.listdir(dataset_dir):\n",
    "#     if not os.path.isdir(os.path.join(dataset_dir, file_name)):\n",
    "#         continue # Not a directory\n",
    "#     class_dir = os.path.join(dataset_dir, file_name)\n",
    "#     for class_file_name in os.listdir(class_dir):\n",
    "#         img_size = Image.open(os.path.join(class_dir, class_file_name)).size\n",
    "#         average_width += img_size[0]\n",
    "#         average_height += img_size[1]\n",
    "#         images_count += 1\n",
    "#     print(file_name, \"avrHei\", average_height/images_count, \"avrWid:\", average_width/images_count)\n",
    "\n",
    "# average_height = 0\n",
    "# average_width = 0\n",
    "# images_count = 0\n",
    "\n",
    "#second experiment to see how the image can be converted and worked on with Image nad pytorch tensor transformation\n",
    "# torch_img_size = (224, 224)\n",
    "# img_path = os.path.join(dataset_dir, \"butterfly\")\n",
    "# listDir = os.listdir(img_path)\n",
    "# img_name = listDir[0]\n",
    "# img_path = os.path.join(img_path, img_name)\n",
    "# #toto nacita obrazok \n",
    "# torchImage = read_image(img_path) / 255.0\n",
    "\n",
    "# second_torch_image = transform(torchImage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c4e188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset classes:  ['butterfly', 'cat', 'chicken', 'cow', 'dog', 'elephant', 'horse', 'sheep', 'spider', 'squirrel']\n",
      "Dataset Size:\t 26179\n",
      "Split sizes:\n",
      "Train:\t\t 18325 \n",
      "Validation:\t 2617 \n",
      "Test:\t\t 5237\n"
     ]
    }
   ],
   "source": [
    "#size of the image that will be after \"normalization\" (setting all the images to the same size)\n",
    "img_size = (224, 224)\n",
    "#transormation that will be used on every image https://docs.pytorch.org/vision/stable/transforms.html\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "analysis_transform = transforms.ToTensor()\n",
    "\n",
    "#loading the dataset with pytorch using ImageFolder https://docs.pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html\n",
    "\n",
    "image_dataset = ImageFolder(\n",
    "    root = dataset_dir, \n",
    "    transform = image_transform \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#if you see ragno, my translate_names.py is not working correctly xd (its spider)\n",
    "print(\"Dataset classes: \", image_dataset.classes)\n",
    "\n",
    "#splitting the dataset to 70% train, 10% validation and 20% train using random_split   https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.random_split\n",
    "\n",
    "dataset_size = len(image_dataset)\n",
    "print(\"Dataset Size:\\t\", dataset_size)\n",
    "train_size = int(0.7 * dataset_size)\n",
    "validation_size   = int(0.1 * dataset_size)\n",
    "test_size  = dataset_size - train_size - validation_size\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset = random_split(image_dataset, [train_size, validation_size, test_size])\n",
    "print(\"Split sizes:\\nTrain:\\t\\t\", len(train_dataset), \"\\nValidation:\\t\", len(validation_dataset), \"\\nTest:\\t\\t\", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ca3ef2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 224, 224])\n",
      "tensor([3, 8, 1, 8, 4, 4, 7, 4, 9, 2])\n"
     ]
    }
   ],
   "source": [
    "#loading the image_dataset to dataLoader https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    shuffle = True, #this shuffles order of images each epoch, random_split randomizes it only once, maybe we dont need this\n",
    "    batch_size = 10  #1 is default, maybe experiment with this later\n",
    ")\n",
    "validation_loader = DataLoader(\n",
    "    dataset = validation_dataset,\n",
    "    shuffle = True,\n",
    "    batch_size = 10  \n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset = test_dataset,\n",
    "    shuffle = True,\n",
    "    batch_size = 10  \n",
    ")\n",
    "\n",
    "#this is how we can iterate through the DataLoader\n",
    "for image_tensor, labels in train_loader:\n",
    "    #shape is [Batch_size, Channels, Height, Width]\n",
    "    print(image_tensor.shape)\n",
    "    #and label (correct class of the image) for each image in tensor (images)\n",
    "    print(labels) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1191ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['butterfly', 'cat', 'chicken', 'cow', 'dog', 'elephant', 'horse', 'sheep', 'spider', 'squirrel']\n"
     ]
    }
   ],
   "source": [
    "#data anylisis here >\n",
    "#loading dataset for data vizualization and analysis\n",
    "analysis_dataset = ImageFolder(\n",
    "    root = dataset_dir,\n",
    "    transform = analysis_transform\n",
    ")\n",
    "analysis_loader = DataLoader(\n",
    "    dataset = analysis_dataset,\n",
    "    shuffle = True,\n",
    "    batch_size = 10  \n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
